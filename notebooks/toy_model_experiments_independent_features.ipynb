{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d088d5cf",
      "metadata": {},
      "source": [
        "# Toy model experiments: Independent features\n",
        "\n",
        "In this notebook, we explore the effect of L0 on SAEs when feature firing independely of each other. This is unrealistic as features always have correlations in reality, but experiments like these are why previously the field though that L0 does not matter as long as it's low enough. We'll use the same setup as in the main toy model experiments notebook, but with independent features (no correlation matrix)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1a13f9",
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sparse_but_wrong.toy_models.get_training_batch import generate_random_correlation_matrix, get_training_batch\n",
        "from sparse_but_wrong.toy_models.toy_model import ToyModel\n",
        "from sparse_but_wrong.toy_models.plotting import SEABORN_RC_CONTEXT\n",
        "from sparse_but_wrong.util import DEFAULT_DEVICE\n",
        "\n",
        "tqdm._instances.clear()  # type: ignore\n",
        "\n",
        "toy_model = ToyModel(num_feats=50, hidden_dim=100).to(DEFAULT_DEVICE)\n",
        "\n",
        "# want 11 features to fire on average\n",
        "feat_probs = torch.ones(50) * 11 / 50\n",
        "generate_batch = partial(\n",
        "    get_training_batch,\n",
        "    firing_probabilities=feat_probs,\n",
        "    std_firing_magnitudes=torch.ones_like(feat_probs) * 0.15,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8aef584d",
      "metadata": {},
      "source": [
        "## Finding the True L0\n",
        "\n",
        "Next, we calculate the true L0 for this dataset (spoiler: it's ~11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d2f1ea7",
      "metadata": {},
      "outputs": [],
      "source": [
        "sample = generate_batch(100_000)\n",
        "true_l0 = (sample > 0).float().sum(dim=-1).mean()\n",
        "print(f\"True L0: {true_l0}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04a8470a",
      "metadata": {},
      "source": [
        "## Training an SAE with the right L0\n",
        "\n",
        "Next, let's train an SAE with the correct L0 and verify it can perfectly recover the underlying true features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e8bd749",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sae_lens import BatchTopKTrainingSAE, BatchTopKTrainingSAEConfig\n",
        "from sparse_but_wrong.toy_models.train_toy_sae import train_toy_sae\n",
        "\n",
        "cfg = BatchTopKTrainingSAEConfig(k=11, d_in=toy_model.embed.weight.shape[0], d_sae=50)\n",
        "sae_full = BatchTopKTrainingSAE(cfg)\n",
        "\n",
        "train_toy_sae(sae_full, toy_model, generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af294427",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sparse_but_wrong.toy_models.plotting import plot_sae_feat_cos_sims, plot_sae_feat_cos_sims_seaborn\n",
        "\n",
        "plot_sae_feat_cos_sims(sae_full, toy_model, \"SAE L0 = True L0\", reorder_features=True, dtick=5)\n",
        "plot_sae_feat_cos_sims_seaborn(sae_full, toy_model, title=\"SAE L0 = True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_eq_true_l0_decoder_cos_sims.pdf\")\n",
        "plot_sae_feat_cos_sims_seaborn(sae_full, toy_model, title=\"SAE L0 = True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_eq_true_l0_decoder_cos_sims.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dc66a9c",
      "metadata": {},
      "source": [
        "As we can see above, the SAE has learned the correct features."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dde3bc76",
      "metadata": {},
      "source": [
        "## What if reduce the L0 below the number of true features?\n",
        "\n",
        "If we lower the L0, then then SAE will need to reconstruct the input with less latents than the number of true features required. How will it handle this? We set L0=9 below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337325f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sparse_but_wrong.enchanced_batch_topk_sae import EnchancedBatchTopKTrainingSAE, EnhancedBatchTopKTrainingSAEConfig\n",
        "from sparse_but_wrong.toy_models.train_toy_sae import train_toy_sae\n",
        "\n",
        "cfg = EnhancedBatchTopKTrainingSAEConfig(k=9, d_in=toy_model.embed.weight.shape[0], d_sae=50, initial_k=14, transition_k_duration_steps=10_000)\n",
        "sae_narrow = EnchancedBatchTopKTrainingSAE(cfg)\n",
        "\n",
        "train_toy_sae(sae_narrow, toy_model, generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cece73e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sparse_but_wrong.toy_models.plotting import plot_sae_feat_cos_sims, plot_sae_feat_cos_sims_seaborn\n",
        "\n",
        "plot_sae_feat_cos_sims(sae_narrow, toy_model, \"SAE L0 < True L0\", reorder_features=True, dtick=5)\n",
        "plot_sae_feat_cos_sims_seaborn(sae_narrow, toy_model, title=\"SAE L0 $<$ True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_lt_true_l0_decoder_cos_sims.pdf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeaeda3a",
      "metadata": {},
      "source": [
        "With independent features the SAE handles this fine! Let's verify this is still the case when we drop the L0 even further."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8551162",
      "metadata": {},
      "source": [
        "## Let's drop the L0 even further!\n",
        "\n",
        "What if we drop the L0 further, so k=5?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8927e492",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sparse_but_wrong.enchanced_batch_topk_sae import EnchancedBatchTopKTrainingSAE, EnhancedBatchTopKTrainingSAEConfig\n",
        "from sparse_but_wrong.toy_models.initialization import init_sae_to_match_model\n",
        "from sparse_but_wrong.toy_models.train_toy_sae import train_toy_sae\n",
        "\n",
        "# transitioning from a higher to lower k seems to help training stability\n",
        "cfg = EnhancedBatchTopKTrainingSAEConfig(k=7, d_in=toy_model.embed.weight.shape[0], d_sae=50, initial_k=15, transition_k_duration_steps=10_000)\n",
        "sae_narrower = EnchancedBatchTopKTrainingSAE(cfg)\n",
        "\n",
        "# init_sae_to_match_model(sae_narrower, toy_model)\n",
        "\n",
        "\n",
        "# NOTE: occasionaly this gets stuck in poor local minima. If this happens, try rerunning and it should converge properly.\n",
        "train_toy_sae(sae_narrower, toy_model, generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d794291e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sparse_but_wrong.toy_models.plotting import plot_sae_feat_cos_sims\n",
        "\n",
        "plot_sae_feat_cos_sims(sae_narrower, toy_model, \"SAE L0 << True L0\", reorder_features=True, dtick=5)\n",
        "plot_sae_feat_cos_sims_seaborn(sae_narrower, toy_model, title=\"SAE L0 $\\\\ll$ True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_llt_true_l0_decoder_cos_sims.pdf\")\n",
        "plot_sae_feat_cos_sims_seaborn(sae_narrower, toy_model, title=\"SAE L0 $<$ True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_llt_true_l0_decoder_cos_sims_v2.pdf\")\n",
        "plot_sae_feat_cos_sims_seaborn(sae_narrower, toy_model, title=\"SAE L0 $\\\\ll$ True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_llt_true_l0_decoder_cos_sims.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1035f4d",
      "metadata": {},
      "source": [
        "The SAE *still* learns the correct features! If only features were independent in reality too..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7cb3d70",
      "metadata": {},
      "source": [
        "## What if we increase the L0 beyond the number of true features?\n",
        "\n",
        "If we increase the L0, then then SAE will have more latents than necessary to reconstruct the input. Will the SAE still do the right thing? We set L0=14 below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b31f363",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sae_lens import BatchTopKTrainingSAE, BatchTopKTrainingSAEConfig\n",
        "from sparse_but_wrong.toy_models.train_toy_sae import train_toy_sae\n",
        "\n",
        "cfg = BatchTopKTrainingSAEConfig(k=14, d_in=toy_model.embed.weight.shape[0], d_sae=50)\n",
        "sae_wide = BatchTopKTrainingSAE(cfg)\n",
        "\n",
        "train_toy_sae(sae_wide, toy_model, generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "845099b4",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sparse_but_wrong.toy_models.plotting import plot_sae_feat_cos_sims, plot_sae_feat_cos_sims_seaborn\n",
        "\n",
        "plot_sae_feat_cos_sims(sae_wide, toy_model, \"SAE L0 > True L0\", reorder_features=True, dtick=5)\n",
        "plot_sae_feat_cos_sims_seaborn(sae_wide, toy_model, title=\"SAE L0 $>$ True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_gt_true_l0_decoder_cos_sims.pdf\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fd6ec34",
      "metadata": {},
      "source": [
        "This is still mostly correct, but the SAE is finding some degenerate local minima. If the L0 is too high, the SAE will still fail to find the correct features despite the features firing independently. Let's see what happens if we increase the L0 even more. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "837ac8f6",
      "metadata": {},
      "source": [
        "## Increase L0 even more!\n",
        "\n",
        "Let's see what happens if we increase the L0 to 18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5407ceca",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sae_lens import BatchTopKTrainingSAE, BatchTopKTrainingSAEConfig\n",
        "from sparse_but_wrong.toy_models.train_toy_sae import train_toy_sae\n",
        "\n",
        "cfg = BatchTopKTrainingSAEConfig(k=18, d_in=toy_model.embed.weight.shape[0], d_sae=50)\n",
        "sae_wider = BatchTopKTrainingSAE(cfg)\n",
        "\n",
        "\n",
        "train_toy_sae(sae_wider, toy_model, generate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "224e63ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sparse_but_wrong.toy_models.plotting import plot_sae_feat_cos_sims, plot_sae_feat_cos_sims_seaborn\n",
        "\n",
        "plot_sae_feat_cos_sims(sae_wider, toy_model, \"SAE L0 >> True L0\", reorder_features=True, dtick=5)\n",
        "plot_sae_feat_cos_sims_seaborn(sae_wider, toy_model, title=\"SAE L0 $\\\\gg$ True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_ggt_true_l0_decoder_cos_sims.pdf\")\n",
        "plot_sae_feat_cos_sims_seaborn(sae_wider, toy_model, title=\"SAE L0 $>$ True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_ggt_true_l0_decoder_cos_sims_v2.pdf\")\n",
        "plot_sae_feat_cos_sims_seaborn(sae_wider, toy_model, title=\"SAE L0 $\\\\gg$ True L0\", reorder_features=True, decoder_only=True, width=5, height=2, dtick=5, decoder_title=None, save_path=\"plots/toy_l0_indep/sae_l0_ggt_true_l0_decoder_cos_sims.png\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da607817",
      "metadata": {},
      "source": [
        "As expected, the SAE is even worse now, using its extra capacity to allow some more degenerate solutions."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
